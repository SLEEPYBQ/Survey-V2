Document: 846-The_Development_of_Human-Robot_Interaction_Design_for_Optimal_Emotional_Expression_in_Social_Robots_Used_by_Older_People_Design_of_Robot_Facial_Expressions_and_Gestures.md
Timestamp: 20250524_150507
================================================================================

## involved_stakeholder
Answer: Elderly individuals aged 65+, robotics experts
Source: Ten elderly individuals (four men and six women) aged 65 years or older participated in the group interviews. [...] A seven-point questionnaire was administered to ten experts (five men and five women) in the field of robotics.

## sample_size
Answer: 10 elderly participants for group interviews, 20 elderly participants for preference evaluation, 10 robotics experts for emotion evaluation, 25 elderly participants for validation evaluation
Source: Ten elderly individuals (four men and six women) aged 65 years or older participated in the group interviews. [...] 20 prospective users aged 65+ participated in the preference evaluation. [...] A seven-point questionnaire was administered to ten experts (five men and five women) in the field of robotics. [...] A total of 25 potential elderly users were presented with a video of the HRI design.

## country
Answer: South Korea
Source: Department of Design Engineering, Tech University of Korea, Siheung 15073, South Korea

## age
Answer: Elderly participants aged 65+
Source: Ten elderly individuals (four men and six women) aged 65 years or older participated in the group interviews.

## gender
Answer: Four men and six women in elderly group interviews; five men and five women among robotics experts
Source: Ten elderly individuals (four men and six women) aged 65 years or older participated in the group interviews. [...] A seven-point questionnaire was administered to ten experts (five men and five women) in the field of robotics.

## demographic_background
Answer: N/A
Source: Not found in the paper

## cognitive_and_physical_impairment
Answer: N/A
Source: Not found in the paper

## needs_and_expectations
Answer: Emotional care through affective support, natural and human-like interactions
Source: This study focuses on social robots that interact with elderly individuals and provide them with emotional care through affective support. [...] The objective of this study is to develop an optimized set of robot facial expressions and gestures that can enable robots to express emotions in a manner similar to humans.

## application_context
Answer: Social robots for elderly individuals in daily life scenarios (e.g., greetings, medication reminders, exercise encouragement)
Source: We constructed an integrated scenario of the interactions between social robots and humans featuring the elderly, from the time they wake up in the morning to the time they go to bed.

## process_of_the_care
Answer: Short-term use during evaluation sessions
Source: A total of 25 potential elderly users were presented with a video of the HRI design, which depicted the robot's facial expressions and gestures. Subsequently, they rated the video on a seven-point scale.

## methodology
Answer: Qualitative group interviews, quantitative surveys, preference evaluations, motion capture analysis
Source: We conducted group interviews using a mood meter. [...] A seven-point questionnaire was administered to ten experts. [...] We conducted a preference evaluation using a seven-point scale. [...] We employed DeepMotion's AI-based motion capture technology to generate motion data.

## care_type
Answer: Emotional care and social interaction
Source: This study focuses on social robots that interact with elderly individuals and provide them with emotional care through affective support.

## robot_type
Answer: Social robot with 2D display face and upper body movement capabilities
Source: The majority of commercially available robots express facial expressions through the use of either two-dimensional (2D) displays or three-dimensional (3D) actuators, with a full-face 2D display being the most common. [...] The exterior design, which directly influences the gesture design, was prioritized.

## robot_name
Answer: N/A
Source: Not found in the paper

## design_goal
Answer: Develop optimized facial expressions and gestures for social robots to express emotions similarly to humans
Source: The objective of this study is to develop an optimized set of robot facial expressions and gestures that can enable robots to express emotions in a manner similar to humans.

## robot_concern_function
Answer: Facial expressions (eyes, eyebrows, mouth, cheeks) and upper body gestures
Source: Accordingly, our robot's face was designed with the eyes, mouth, eyebrows, and cheeks in mind. [...] The gesture element pertains to the emotional behavior of a robot.

## facilitating_functions
Answer: Human-like facial expressions and gestures to enhance emotional connection
Source: By analyzing human facial expressions and gestures in relation to emotions and applying these findings to robots, we successfully developed natural and emotionally expressive robot behaviors.

## inhibitory_functions
Answer: Overly exaggerated facial expressions or gestures that hinder natural interaction
Source: The users indicated that the facial expressions were overly exaggerated compared to the gestures. [...] The users indicated that the facial expressions, particularly the angles of the eyebrows and the shapes of the eyes and mouth, were overly exaggerated, leading to an imbalance with the gestures.

## stakeholder_facilitating_characteristics
Answer: Preference for geometric and simplified facial designs, natural gesture patterns
Source: The Type B face design, characterized by geometric eyes and other components, achieved the highest mean score (5.55). [...] The acceleration graph of the final movement should be modified to exhibit a downward curve, thereby facilitating a natural transition to the subsequent movement.

## stakeholder_inhibitory_characteristics
Answer: Difficulty understanding overly mechanical or exaggerated expressions/gestures
Source: The facial expressions and gestures of modern social robots are often simplistic and mechanical in nature, hindering their ability to convey emotions accurately. [...] The users indicated that the facial expressions were overly intense compared to the gestures.

## engagement
Answer: High engagement with natural facial expressions and gestures (average scores of 5.5+ in reevaluation)
Source: The revised ''joyful,'' ''concerned,'' and ''grateful'' facial expressions and gesture designs were subjected to a second evaluation by a sample of 25 prospective users of the social robot. [...] For all designs, the average score was 5.5 or higher.

## acceptance
Answer: Positive acceptance of robot's emotional expressions (e.g., ''loving'' emotion scored 5.9/7)
Source: The ''loving'' emotion facial expressions and gesture design received an average rating of 5.9 on a seven-point scale.

## trust
Answer: N/A (implied through emotional connection but not explicitly measured)
Source: Not found in the paper

## key_findings
Answer: Developed facial expression and gesture designs for six emotions (Loving, Joyful, Upbeat, Hopeful, Concerned, Grateful) that enhance emotional interaction with elderly users
Source: As a result of the study, we developed facial expression and gesture designs for six emotions (Loving, Joyful, Upbeat, Hopeful, Concerned, Grateful) in social robots interacting with elderly individuals.

## additional_info
Answer: Limitations include lack of emotional intensity variations and cultural adaptability; future research should address these
Source: This study is constrained by the fact that it presents a single facial expression and gesture for each emotion, which does not account for the potential variations in emotional intensity. [...] Emotional expressions can vary in interpretation and application depending on cultural differences and individual characteristics.

## testing_context
Answer: Lab setting for evaluations (video presentations of robot interactions)
Source: A total of 25 potential elderly users were presented with a video of the HRI design, which depicted the robot's facial expressions and gestures.